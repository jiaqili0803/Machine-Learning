{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWTe9VS3_b11"
   },
   "source": [
    "## SI 670 Applied Machine Learning, Week 6:  Naive Bayes, Boosting Algorithms, Pipeline. (Due 10/12 11:59pm)\n",
    "\n",
    "For this assignment, you will be revisiting concepts including Naive Bayes, boosting algorithms and pipelines.\n",
    "\n",
    "* This homework is worth 100 points in total. Correct answers and code receive full credit, but partial credit will be awarded if you have the right idea even if your final answers aren't quite right.\n",
    "\n",
    "* Submit your completed notebook file to the Canvas site - **IMPORTANT**: please name your submitted file `si670f22-hw6-youruniqname.ipynb`\n",
    "\n",
    "* Any file submitted after the deadline will be marked as late. Please consult the syllabus regarding late submission policies. You can submit the homework as many time as you want, but only your latest submission will be graded.\n",
    "\n",
    "* As a reminder, the notebook code you submit must be your own work. Feel free to discuss general approaches to the homework with classmates. If you end up forming more of a team discussion on multiple questions, please include the names of the people you worked with at the top of your notebook file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mV6sI-nIuou"
   },
   "source": [
    "### Collaborators, if any:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0zI1Jx5Iuov"
   },
   "source": [
    "### Question 1 (20 points)\n",
    "\n",
    "Please write the answers as well as your derivation process of the following questions. You can use either LaTeX or python code to represent your answer. For example, if you want to present <$x_1^2$>, in the LaTeX format you should write <(dollar sign) x_1^2 (dollar sign)>; in the python code format you should write <\\`x_1\\*\\*2\\`>. See [here](https://csrgxtu.github.io/2015/03/20/Writing-Mathematic-Fomulars-in-Markdown/) for how to represent more mathmatical symbols in LaTeX format.\n",
    "\n",
    "**Calculate the unnormalized posterior probability of a naive Bayes classifier**\n",
    "\n",
    "Suppose you have a dataset with 2 features $X_1, X_2$ and a binary label $Y$. $X_1$ and $Y$ takes value either 0 or 1. $X_2$ takes one out of the three possible values $0, 1$, or $2$.\n",
    "\n",
    "Based on the dataset, you know \n",
    "\n",
    "$p(Y=0) = 0.05$, \n",
    "\n",
    "$p(X_1=0 | Y=0) = 0.6$, $p(X_1=0 | Y=1) = 0.3$, \n",
    "\n",
    "$p(X_2=0 | Y=0) = 0.9$, $p(X_2=1 | Y=0) = 0.05$, $p(X_2=0 | Y=1) = 0.1$, $p(X_2=1 | Y=1) = 0.3$. \n",
    "\n",
    "Please calculate the unnormalized posterior probability of a naive Bayes classifier: \n",
    "$$\\hat{p}(Y=1 | X) = p(X | Y=1) p(Y=1)$$ and $$\\hat{p}(Y=0 | X) = p(X | Y=0) p(Y=0)$$ of the following data points.\n",
    "\n",
    "#### (a) (10 points) $X_1 = 1, X_2 = 0$\n",
    "\n",
    "\n",
    "\n",
    "#### (b) (10 points) $X_1 = 0, X_2 = 2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kxKnU9PIuow"
   },
   "source": [
    "### Answer 1\n",
    "\n",
    "(a) \n",
    "\n",
    "$$\\hat{p}(Y=1 | X) = p(X | Y=1) p(Y=1)$$ = $$p(X_1=1| Y=1)p(X_2=0 | Y=1) (1-p(Y=0))$$ = $$(1-0.3)*(0.1)*(0.95)$$ = $$0.7*0.1*0.95$$ = 0.0665\n",
    "\n",
    "$$\\hat{p}(Y=0 | X) = p(X | Y=0) p(Y=0)$$ = $$p(X_1=1| Y=0)p(X_2=0 | Y=0) p(Y=0)$$ = $$(1-0.6)(0.9)(0.05)$$ = 0.018\n",
    "\n",
    "\n",
    "\n",
    "(b)\n",
    "$$\\hat{p}(Y=1 | X) = p(X | Y=1) p(Y=1)$$ = $$p(X_1=0| Y=1)p(X_2=2 | Y=1) (1-p(Y=0))$$ = $$(0.3)*(1-0.1-0.3)*(1-0.05)$$ = 0.171\n",
    "\n",
    "$$\\hat{p}(Y=0 | X) = p(X | Y=0) p(Y=0)$$ = $$p(X_1=0| Y=0)p(X_2=2 | Y=0) p(Y=0)$$ = $$0.6*(1-0.9-0.05)*(0.05)$$ = 0.0015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yr0hicxiTSDJ"
   },
   "source": [
    "### Question 2 (40 points)\n",
    "\n",
    "For this question, you will be implementing a gradient boosted decision tree using the `GradientBoostedClassifier` from `sklearn`. Your goal is to find the best set of hyperparameters for this classifier using the tools you have seen previously in this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oe31QZiEkwi7"
   },
   "source": [
    "#### (a) (10 points) \n",
    "Consider the parameters `learning_rate` and `n_estimators` (which represents the number of small trees or weak learners). The documentation for `GradientBoostingClassifier` mentions that \"There is a trade-off between learning_rate and n_estimators\". Why do you think this is the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztoKY6J-lI5G"
   },
   "source": [
    "* Your answer for 2(a) here:\n",
    "* n_estimators sets # of small decision trees to use (weak learners) in the ensemble, which can cause overfit, the learning rate controls emphasis on fixing errors from previous iteration, which can shrink the contribution of each tree. Control overfit. so it is a trade-off between these two. Usually the n_estimators is adjusted first, and tune with the learning rate together.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feeb_ejjV5eO"
   },
   "source": [
    "#### (b) (20 points) \n",
    "\n",
    "Now for the implementation part. First, use `MinMaxScaler` to scale the breast cancer data (be careful about data leakage). Then, use `GridSearchCV` (similar to how you have used it in previous homeworks) in order to find the best `learning_rate`, `n_estimators` and `max_depth` parameters for a gradient boosted decision tree implemented by `GradientBoostingClassifier`.\n",
    "\n",
    "Please search `learning_rate` from `[0.1, 1, 10]`, `n_estimators` from `[1, 5, 10, 100]`, and `max_depth` from `[3, 5]`.\n",
    "\n",
    "Please return the best hyperparameters on cross-validation, as well as the training and test scores associated with these hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qI9ShXOqV7mT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 100, 3, 0.972027972027972)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def run_gridsearch_gboost():\n",
    "    # load data\n",
    "    (X_cancer, y_cancer) = load_breast_cancer(return_X_y = True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state = 0)\n",
    "\n",
    "    # scale\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # tune with GridSearchCV\n",
    "    parameters = {'learning_rate':[0.1,1,10], 'n_estimators':[1, 5, 10, 100], 'max_depth':[3,5]}\n",
    "    clf = GridSearchCV(GradientBoostingClassifier(), parameters)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # best parameters\n",
    "    best_learning_rate = clf.best_params_['learning_rate']\n",
    "    best_n_estimators = clf.best_params_['n_estimators']\n",
    "    best_max_depth = clf.best_params_['max_depth']\n",
    "    \n",
    "    # test\n",
    "    test_score = clf.score(X_test_scaled, y_test)\n",
    "    # GridSearchCV do performed cross-validation\n",
    "\n",
    "    return best_learning_rate, best_n_estimators, best_max_depth, test_score\n",
    "\n",
    "run_gridsearch_gboost()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPBo-S3Isv4a"
   },
   "source": [
    "#### (c) (10 points)\n",
    "\n",
    "So far in lab and homework problems, we have been using scalers to scale the training and test data before applying `GridSearchCV` to find the best model. Does this approach systematically bias the test score? Why, then, should you not use this approach in practice? *(Hint: think about validation)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWnLDFBQzU0c"
   },
   "source": [
    "* Your answer for 2(c) here:\n",
    "* Yes, this approach (scale before applying GridSearchCV) will systematically bias the test score. Because the validation data in cross validation part will use the scaled and data leakaged data and info.\n",
    "\n",
    "* Instead, we can use pipelines. We can assemble the scaler and models in a pipeline then use it as the estimator for GridSearchCV. Pipeline will automatically fit and transform your training data in each fold, and transform on validation set using fitted scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Du1y12kIIuo1"
   },
   "source": [
    "### Question 3 (40 points)\n",
    "\n",
    "We will solve the issue raised in 2(c) here using a pipeline. While you are answer this question, think about why a pipeline is helpful in addressing the issue from 2(c) (You do not need to write down your thoughts for this question).\n",
    "\n",
    "Build a pipeline that first applies the MinMaxScaler to the data and then grid searches the hyper-parameter `C` of the `LinearSVC` classifier. Note the whole process should be wrapped in a single pipeline.\n",
    "\n",
    "Return a tuple `(pipe, test_score)`, where `pipe` is the pipeline object you build and `test_score` is the accuracy score you get from your final model on `(X_test, y_test)`.\n",
    "\n",
    "The grid search range of the parameter is given in `param_grid`.\n",
    "\n",
    "*Hint1: The `GridSearchCV` itself can be viewed as a classifier or a regressor because it implements `.fit` and `.score` functions.*\n",
    "\n",
    "*Hint2: There are two ways to combine `GridSearchCV` and `Pipeline`: you can either grid search a pipeline with the scaler and the classifier; or you can pipeline the scaler and the \"grid-search classifier\". This question requires you to implement the latter one. Think about which way is more computationally efficient?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qPKprqe7Iuo1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiaqi\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jiaqi\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jiaqi\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jiaqi\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jiaqi\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jiaqi\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('scaler', MinMaxScaler()), ('clf', LinearSVC())]),\n",
       " GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                        ('clf', LinearSVC())]),\n",
       "              param_grid={'clf__C': [0.1, 1, 10, 100]}),\n",
       " 0.958041958041958)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # get data, split data\n",
    "    (X_cancer, y_cancer) = load_breast_cancer(return_X_y = True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state = 0)\n",
    "\n",
    "    # parameter\n",
    "    param_grid = {\"clf__C\": [0.1, 1, 10, 100]}\n",
    "    \n",
    "    # build pipeline\n",
    "    components = [('scaler', MinMaxScaler()), ('clf', LinearSVC())]\n",
    "    pipe = Pipeline(components)\n",
    "    \n",
    "    # grid search a pipeline (with the scaler and the classifier)\n",
    "    grid = GridSearchCV(pipe, param_grid) \n",
    "    \n",
    "    # GridSearchCV itself can be viewed as a classifier, can implement .fit and .score functions\n",
    "    grid.fit(X_train, y_train)\n",
    "    test_score = grid.score(X_test, y_test)\n",
    "\n",
    "    return pipe, grid, test_score\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I return both the pipe and grid, because the changing announcement did not say return which one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Think about which way is more computationally efficient?\n",
    "\n",
    "1. grid search a pipeline with the scaler and the classifier; \n",
    "2. pipeline the scaler and the \"grid-search classifier\"\n",
    "\n",
    "* The 2nd method will call the Scalar only once when fit(), so it might be more computationally efficient, but it leads to data leakage (tune the hyperparameters on the data already preprocessed by Scaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
